{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of this article\n",
    "\n",
    "https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tensor([1, 2, 3]); a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Life is short, eat dessert first'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc = {s:i for i, s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 5, 2, 1, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_int = tensor(\n",
    "    [dc[s] for s in sentence.replace(',', '').split()]\n",
    ")\n",
    "sentence_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 50_000\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embed = torch.nn.Embedding(vocab_size, 3)\n",
    "embedded_sentence = embed(sentence_int).detach()\n",
    "embedded_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3374, -0.1778, -0.3035],\n",
       "        [ 0.1794,  1.8951,  0.4954],\n",
       "        [ 0.2692, -0.0770, -1.0205],\n",
       "        [-0.2196, -0.3792,  0.7671],\n",
       "        [-0.5880,  0.3486,  0.6603],\n",
       "        [-1.1925,  0.6984, -1.4097]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = embedded_sentence.shape[1]\n",
    "d_q, d_k, d_v = 2, 2, 4\n",
    "\n",
    "# this makes it so that tensors have requires_grad True\n",
    "W_query = nn.Parameter(torch.rand(d,d_q))\n",
    "W_key = nn.Parameter(torch.rand(d,d_k))\n",
    "W_value = nn.Parameter(torch.rand(d,d_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_query.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2, 3)\n",
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = embedded_sentence[1]\n",
    "# x_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "value_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 2]), torch.Size([6, 4]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = embedded_sentence @ W_key\n",
    "values = embedded_sentence @ W_value\n",
    "keys.shape, values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0996,  2.9454, -0.6374, -0.0801,  0.3291, -1.5970],\n",
       "       grad_fn=<MvBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention weights unnormalized\n",
    "\n",
    "omega_2 = query_2 @ keys.T\n",
    "omega_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights_2 = F.softmax(omega_2 / d_k**0.5, dim=0)\n",
    "attention_weights_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3511, 0.2289, 0.8308, 0.7071], grad_fn=<MvBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector_2 = attention_weights_2 @ values\n",
    "context_vector_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out_kq, d_out_v):\n",
    "        super().__init__()\n",
    "        self.d_out_kq = d_out_kq\n",
    "        # print(d_out_v)\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out_v))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_q = x @ self.W_query # [B, d_out_kq]\n",
    "        x_k = x @ self.W_key # [B, d_out_kq]\n",
    "        x_v = x @ self.W_value # [B, d_out_v]\n",
    "        u_attention_weights = x_q @ x_k.T\n",
    "        attention_weights = F.softmax(u_attention_weights / self.d_out_kq ** 0.5, dim=-1) # [B, B]\n",
    "        context_vector = attention_weights @ x_v\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "self_attention = SelfAttention(d_in=3, d_out_kq=2, d_out_v=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2921, -0.0851,  0.1581,  0.0157],\n",
       "        [ 0.3511,  0.2289,  0.8308,  0.7071],\n",
       "        [-0.3952, -0.1419,  0.0867, -0.0524],\n",
       "        [-0.2784, -0.0533,  0.1878,  0.0059],\n",
       "        [-0.1756, -0.0231,  0.2559,  0.1114],\n",
       "        [-0.5338, -0.2074,  0.0257, -0.1290]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention(embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (3, 2, 4)\n",
    "self_attention = SelfAttention(*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2921, -0.0851,  0.1581,  0.0157],\n",
       "        [ 0.3511,  0.2289,  0.8308,  0.7071],\n",
       "        [-0.3952, -0.1419,  0.0867, -0.0524],\n",
       "        [-0.2784, -0.0533,  0.1878,  0.0059],\n",
       "        [-0.1756, -0.0231,  0.2559,  0.1114],\n",
       "        [-0.5338, -0.2074,  0.0257, -0.1290]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention(embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self, d_in, d_out_kq, d_out_v, num_heads):\n",
    "        super().__init__()\n",
    "        print(d_in, d_out_kq, d_out_v, num_heads)\n",
    "        self.heads = nn.ModuleList(\n",
    "            [SelfAttention(d_in, d_out_kq, d_out_v) for _ in range(num_heads)]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 1 3\n"
     ]
    }
   ],
   "source": [
    "mh_attention = MultiHeadAttentionWrapper(3, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh_attention(embedded_sentence).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "sa = SelfAttention(3, 2, 1)\n",
    "print(sa(embedded_sentence).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out_kq, d_out_v):\n",
    "        super().__init__()\n",
    "        self.d_out_kq = d_out_kq\n",
    "        # print(d_out_v)\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out_v))\n",
    "    \n",
    "    def forward(self, x1, x2):  # x_2 is new\n",
    "        x_q = x1 @ self.W_query # [B, d_out_kq]\n",
    "        x_k = x2 @ self.W_key # [B, d_out_kq]\n",
    "        x_v = x2 @ self.W_value # [B, d_out_v]\n",
    "        u_attention_weights = x_q @ x_k.T\n",
    "        attention_weights = F.softmax(u_attention_weights / self.d_out_kq ** 0.5, dim=-1) # [B, B]\n",
    "        context_vector = attention_weights @ x_v\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = embedded_sentence.shape[0]; block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_simple = torch.tril(torch.ones(block_size, block_size))\n",
    "mask_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
